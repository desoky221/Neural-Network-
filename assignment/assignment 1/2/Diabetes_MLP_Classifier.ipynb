{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78e091d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# youssef ahmed ibrahim \n",
    "# 223101109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c95aeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e738e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100000, 31)\n",
      "\n",
      "First few rows:\n",
      "   age  gender ethnicity education_level  income_level employment_status  \\\n",
      "0   58    Male     Asian      Highschool  Lower-Middle          Employed   \n",
      "1   48  Female     White      Highschool        Middle          Employed   \n",
      "2   60    Male  Hispanic      Highschool        Middle        Unemployed   \n",
      "3   74  Female     Black      Highschool           Low           Retired   \n",
      "4   46    Male     White        Graduate        Middle           Retired   \n",
      "\n",
      "  smoking_status  alcohol_consumption_per_week  \\\n",
      "0          Never                             0   \n",
      "1         Former                             1   \n",
      "2          Never                             1   \n",
      "3          Never                             0   \n",
      "4          Never                             1   \n",
      "\n",
      "   physical_activity_minutes_per_week  diet_score  ...  hdl_cholesterol  \\\n",
      "0                                 215         5.7  ...               41   \n",
      "1                                 143         6.7  ...               55   \n",
      "2                                  57         6.4  ...               66   \n",
      "3                                  49         3.4  ...               50   \n",
      "4                                 109         7.2  ...               52   \n",
      "\n",
      "   ldl_cholesterol  triglycerides  glucose_fasting  glucose_postprandial  \\\n",
      "0              160            145              136                   236   \n",
      "1               50             30               93                   150   \n",
      "2               99             36              118                   195   \n",
      "3               79            140              139                   253   \n",
      "4              125            160              137                   184   \n",
      "\n",
      "   insulin_level  hba1c  diabetes_risk_score  diabetes_stage  \\\n",
      "0           6.36   8.18                 29.6          Type 2   \n",
      "1           2.00   5.63                 23.0     No Diabetes   \n",
      "2           5.07   7.51                 44.7          Type 2   \n",
      "3           5.28   9.03                 38.2          Type 2   \n",
      "4          12.74   7.20                 23.5          Type 2   \n",
      "\n",
      "   diagnosed_diabetes  \n",
      "0                   1  \n",
      "1                   0  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   1  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 31 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   age                                 100000 non-null  int64  \n",
      " 1   gender                              100000 non-null  object \n",
      " 2   ethnicity                           100000 non-null  object \n",
      " 3   education_level                     100000 non-null  object \n",
      " 4   income_level                        100000 non-null  object \n",
      " 5   employment_status                   100000 non-null  object \n",
      " 6   smoking_status                      100000 non-null  object \n",
      " 7   alcohol_consumption_per_week        100000 non-null  int64  \n",
      " 8   physical_activity_minutes_per_week  100000 non-null  int64  \n",
      " 9   diet_score                          100000 non-null  float64\n",
      " 10  sleep_hours_per_day                 100000 non-null  float64\n",
      " 11  screen_time_hours_per_day           100000 non-null  float64\n",
      " 12  family_history_diabetes             100000 non-null  int64  \n",
      " 13  hypertension_history                100000 non-null  int64  \n",
      " 14  cardiovascular_history              100000 non-null  int64  \n",
      " 15  bmi                                 100000 non-null  float64\n",
      " 16  waist_to_hip_ratio                  100000 non-null  float64\n",
      " 17  systolic_bp                         100000 non-null  int64  \n",
      " 18  diastolic_bp                        100000 non-null  int64  \n",
      " 19  heart_rate                          100000 non-null  int64  \n",
      " 20  cholesterol_total                   100000 non-null  int64  \n",
      " 21  hdl_cholesterol                     100000 non-null  int64  \n",
      " 22  ldl_cholesterol                     100000 non-null  int64  \n",
      " 23  triglycerides                       100000 non-null  int64  \n",
      " 24  glucose_fasting                     100000 non-null  int64  \n",
      " 25  glucose_postprandial                100000 non-null  int64  \n",
      " 26  insulin_level                       100000 non-null  float64\n",
      " 27  hba1c                               100000 non-null  float64\n",
      " 28  diabetes_risk_score                 100000 non-null  float64\n",
      " 29  diabetes_stage                      100000 non-null  object \n",
      " 30  diagnosed_diabetes                  100000 non-null  int64  \n",
      "dtypes: float64(8), int64(16), object(7)\n",
      "memory usage: 23.7+ MB\n",
      "None\n",
      "\n",
      "Class distribution:\n",
      "diagnosed_diabetes\n",
      "1    59998\n",
      "0    40002\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"A:\\future\\collage\\sem 5\\NN\\assignment\\1\\diabetes_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['diagnosed_diabetes'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "773b50be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "age                                   0\n",
      "gender                                0\n",
      "ethnicity                             0\n",
      "education_level                       0\n",
      "income_level                          0\n",
      "employment_status                     0\n",
      "smoking_status                        0\n",
      "alcohol_consumption_per_week          0\n",
      "physical_activity_minutes_per_week    0\n",
      "diet_score                            0\n",
      "sleep_hours_per_day                   0\n",
      "screen_time_hours_per_day             0\n",
      "family_history_diabetes               0\n",
      "hypertension_history                  0\n",
      "cardiovascular_history                0\n",
      "bmi                                   0\n",
      "waist_to_hip_ratio                    0\n",
      "systolic_bp                           0\n",
      "diastolic_bp                          0\n",
      "heart_rate                            0\n",
      "cholesterol_total                     0\n",
      "hdl_cholesterol                       0\n",
      "ldl_cholesterol                       0\n",
      "triglycerides                         0\n",
      "glucose_fasting                       0\n",
      "glucose_postprandial                  0\n",
      "insulin_level                         0\n",
      "hba1c                                 0\n",
      "diabetes_risk_score                   0\n",
      "diabetes_stage                        0\n",
      "diagnosed_diabetes                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9585ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15294be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Removing data leakage columns...\n",
      "Removed: diabetes_stage, diabetes_risk_score\n",
      "\n",
      "Encoding categorical variables...\n",
      "\n",
      "Original features (with leakage): 30\n",
      "Features after removing leakage and encoding: 40\n",
      "\n",
      "Features shape: (100000, 40)\n",
      "Labels shape: (100000,)\n",
      "\n",
      "Feature scaling completed.\n",
      "Mean of scaled features: -0.000000\n",
      "Std of scaled features: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Remove data leakage columns \n",
    "# diabetes_stage: literally tells if someone has diabetes (Type 2, No Diabetes, etc.)\n",
    "# diabetes_risk_score: likely calculated based on diagnosis\n",
    "print(\"⚠️ Removing data leakage columns...\")\n",
    "df_clean = df.drop(['diabetes_stage', 'diabetes_risk_score'], axis=1)\n",
    "print(f\"Removed: diabetes_stage, diabetes_risk_score\\n\")\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = ['gender', 'ethnicity', 'education_level', 'income_level', \n",
    "                    'employment_status', 'smoking_status']\n",
    "\n",
    "print(\"Encoding categorical variables...\")\n",
    "df_encoded = pd.get_dummies(df_clean, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(f\"\\nOriginal features (with leakage): {df.shape[1] - 1}\")\n",
    "print(f\"Features after removing leakage and encoding: {df_encoded.shape[1] - 1}\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_encoded.drop('diagnosed_diabetes', axis=1).values\n",
    "y = df_encoded['diagnosed_diabetes'].values\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"\\nFeature scaling completed.\")\n",
    "print(f\"Mean of scaled features: {X_scaled.mean():.6f}\")\n",
    "print(f\"Std of scaled features: {X_scaled.std():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3756fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 100000\n",
      "Training samples: 80000\n",
      "Testing samples: 20000\n",
      "\n",
      "Number of training batches: 313\n",
      "Number of testing batches: 79\n"
     ]
    }
   ],
   "source": [
    "full_dataset = DiabetesDataset(X_scaled, y)\n",
    "\n",
    "train_len = int(0.8 * len(full_dataset))\n",
    "test_len = len(full_dataset) - train_len\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_len, test_len])\n",
    "\n",
    "print(f\"Total samples: {len(full_dataset)}\")\n",
    "print(f\"Training samples: {train_len}\")\n",
    "print(f\"Testing samples: {test_len}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f\"\\nNumber of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of testing batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a187721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ce098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=40, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.2, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (13): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=32, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total parameters: 54754\n",
      "Trainable parameters: 54754\n"
     ]
    }
   ],
   "source": [
    "input_dim = X.shape[1]\n",
    "num_classes = 2 \n",
    "\n",
    "model = MLPClassifier(input_dim=input_dim, num_classes=num_classes)\n",
    "\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6793c684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa5a23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for features, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a62658ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(test_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels, all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00ade05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/313 [00:00<?, ?it/s]C:\\Users\\youssef desoky\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 200.92it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 616.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3382, Train Acc: 85.20%\n",
      "Test Loss: 0.2752, Test Acc: 88.50%\n",
      "\n",
      "Epoch [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [00:01<00:00, 207.49it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 615.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2818, Train Acc: 88.20%\n",
      "Test Loss: 0.2569, Test Acc: 89.53%\n",
      "\n",
      "Epoch [3/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [00:01<00:00, 207.10it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 603.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2681, Train Acc: 88.87%\n",
      "Test Loss: 0.2502, Test Acc: 90.09%\n",
      "\n",
      "Epoch [4/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [00:01<00:00, 228.12it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 620.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2617, Train Acc: 89.30%\n",
      "Test Loss: 0.2466, Test Acc: 90.08%\n",
      "\n",
      "Epoch [5/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [00:01<00:00, 206.92it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 461.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2589, Train Acc: 89.48%\n",
      "Test Loss: 0.2435, Test Acc: 90.51%\n",
      "\n",
      "Epoch [6/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [00:01<00:00, 179.64it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 546.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2556, Train Acc: 89.68%\n",
      "Test Loss: 0.2422, Test Acc: 90.47%\n",
      "\n",
      "Epoch [7/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [00:02<00:00, 150.28it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 403.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2541, Train Acc: 89.79%\n",
      "Test Loss: 0.2401, Test Acc: 90.75%\n",
      "\n",
      "Epoch [8/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [00:02<00:00, 131.98it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 436.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2497, Train Acc: 89.99%\n",
      "Test Loss: 0.2433, Test Acc: 90.69%\n",
      "\n",
      "Epoch [9/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [00:01<00:00, 170.04it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 484.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2505, Train Acc: 89.87%\n",
      "Test Loss: 0.2351, Test Acc: 90.70%\n",
      "\n",
      "Epoch [10/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [00:01<00:00, 172.33it/s]\n",
      "Evaluating: 100%|██████████| 79/79 [00:00<00:00, 513.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2485, Train Acc: 90.07%\n",
      "Test Loss: 0.2379, Test Acc: 90.88%\n",
      "\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    \n",
    "    # Evaluate \n",
    "    test_loss, test_acc, _, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
